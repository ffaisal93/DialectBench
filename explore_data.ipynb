{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cee494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datasets import load_dataset, load_from_disk, DatasetDict\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0b48c1",
   "metadata": {},
   "source": [
    "- get data:\n",
    "    - `./download_data.sh --task all`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06699845",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR='.cache'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c0042b",
   "metadata": {},
   "source": [
    "### 1. parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "032ef6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_langs=[\n",
    "    \"UD_Armenian-ArmTDP\", \"UD_Norwegian-Nynorsk\", \"UD_Portuguese-Bosque\", \"UD_Italian-PoSTWITA\", \"UD_Old_French-SRCMF\", \"UD_North_Sami-Giella\", \"UD_Norwegian-Bokmaal\", \"UD_French-ParisStories\", \"UD_Italian-MarkIT\", \"UD_Chinese-GSDSimp\", \"UD_English-EWT\", \"UD_French-Rhapsodie\", \"UD_French-ParTUT\", \"UD_Classical_Chinese-Kyoto\", \"UD_Norwegian-NynorskLIA\", \"UD_Arabic-NYUAD\", \"UD_Portuguese-PetroGold\", \"UD_Italian-TWITTIRO\", \"UD_Turkish_German-SAGT\", \"UD_Maghrebi_Arabic_French-Arabizi\", \"UD_Portuguese-CINTIL\", \"UD_Ligurian-GLT\", \"UD_Dutch-Alpino\", \"UD_Western_Armenian-ArmTDP\", \"UD_Portuguese-GSD\", \"singlish\", \"UD_Arabic-PADT\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b34856e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UD_Armenian-ArmTDP', 'UD_Norwegian-Nynorsk', 'UD_Portuguese-Bosque', 'UD_Italian-PoSTWITA', 'UD_Old_French-SRCMF', 'UD_North_Sami-Giella', 'UD_Norwegian-Bokmaal', 'UD_French-ParisStories', 'UD_Italian-MarkIT', 'UD_Chinese-GSDSimp', 'UD_English-EWT', 'UD_French-Rhapsodie', 'UD_French-ParTUT', 'UD_Classical_Chinese-Kyoto', 'UD_Norwegian-NynorskLIA', 'UD_Arabic-NYUAD', 'UD_Portuguese-PetroGold', 'UD_Italian-TWITTIRO', 'UD_Turkish_German-SAGT', 'UD_Maghrebi_Arabic_French-Arabizi', 'UD_Portuguese-CINTIL', 'UD_Ligurian-GLT', 'UD_Dutch-Alpino', 'UD_Western_Armenian-ArmTDP', 'UD_Portuguese-GSD', 'singlish', 'UD_Arabic-PADT']\n"
     ]
    }
   ],
   "source": [
    "print(train_langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7e95067",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('metadata/udp_metadata.json')\n",
    "metadata = json.load(f)\n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0255012",
   "metadata": {},
   "source": [
    "- we finetune each lang where train split available\n",
    "- if train split not available, we perform zero-shot from UD_English-EWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ffb7764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lang</th>\n",
       "      <th>code</th>\n",
       "      <th>desc</th>\n",
       "      <th>langgroup</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>singlish</td>\n",
       "      <td>singlish</td>\n",
       "      <td>eng-sing</td>\n",
       "      <td></td>\n",
       "      <td>English</td>\n",
       "      <td>[dev, test, train]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UD_Armenian-ArmTDP</td>\n",
       "      <td>Armenian</td>\n",
       "      <td>hye-east</td>\n",
       "      <td></td>\n",
       "      <td>Armenian</td>\n",
       "      <td>[train, test, dev]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UD_French-ParTUT</td>\n",
       "      <td>French</td>\n",
       "      <td>fre-multigenre</td>\n",
       "      <td></td>\n",
       "      <td>French</td>\n",
       "      <td>[train, dev, test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UD_English-EWT</td>\n",
       "      <td>English</td>\n",
       "      <td>eng</td>\n",
       "      <td></td>\n",
       "      <td>English</td>\n",
       "      <td>[dev, test, train]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UD_Ligurian-GLT</td>\n",
       "      <td>Ligurian</td>\n",
       "      <td>lij</td>\n",
       "      <td></td>\n",
       "      <td>Italian</td>\n",
       "      <td>[train, test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UD_Gheg-GPS</td>\n",
       "      <td>Gheg</td>\n",
       "      <td>aln</td>\n",
       "      <td></td>\n",
       "      <td>Albanian</td>\n",
       "      <td>[test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UD_Norwegian-Nynorsk</td>\n",
       "      <td>Norwegian</td>\n",
       "      <td>nor-nynorsk</td>\n",
       "      <td></td>\n",
       "      <td>Norwegian</td>\n",
       "      <td>[test, dev, train]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UD_Albanian-TSA</td>\n",
       "      <td>Albanian</td>\n",
       "      <td>alb</td>\n",
       "      <td></td>\n",
       "      <td>Albanian</td>\n",
       "      <td>[test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UD_Italian-PUD</td>\n",
       "      <td>Italian</td>\n",
       "      <td>ita-trans</td>\n",
       "      <td></td>\n",
       "      <td>Italian</td>\n",
       "      <td>[test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UD_Portuguese-Bosque</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>por-euro-bra</td>\n",
       "      <td></td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>[test, dev, train]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  index        lang            code desc   langgroup  \\\n",
       "0              singlish    singlish        eng-sing          English   \n",
       "1    UD_Armenian-ArmTDP    Armenian        hye-east         Armenian   \n",
       "2      UD_French-ParTUT      French  fre-multigenre           French   \n",
       "3        UD_English-EWT     English             eng          English   \n",
       "4       UD_Ligurian-GLT    Ligurian             lij          Italian   \n",
       "5           UD_Gheg-GPS        Gheg             aln         Albanian   \n",
       "6  UD_Norwegian-Nynorsk   Norwegian     nor-nynorsk        Norwegian   \n",
       "7       UD_Albanian-TSA    Albanian             alb         Albanian   \n",
       "8        UD_Italian-PUD     Italian       ita-trans          Italian   \n",
       "9  UD_Portuguese-Bosque  Portuguese    por-euro-bra       Portuguese   \n",
       "\n",
       "                split  \n",
       "0  [dev, test, train]  \n",
       "1  [train, test, dev]  \n",
       "2  [train, dev, test]  \n",
       "3  [dev, test, train]  \n",
       "4       [train, test]  \n",
       "5              [test]  \n",
       "6  [test, dev, train]  \n",
       "7              [test]  \n",
       "8              [test]  \n",
       "9  [test, dev, train]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lang=pd.DataFrame(metadata).T\n",
    "all_lang.reset_index(level=0, inplace=True)\n",
    "# all_lang['lang-code'] = list(all_lang.index)\n",
    "all_lang.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88b24761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Armenian-ArmTDP/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 131.30it/s]\n"
     ]
    }
   ],
   "source": [
    "#explore a single lang\n",
    "lang='UD_Armenian-ArmTDP'\n",
    "dataset = load_dataset(\"scripts/universal_dependencies.py\", lang,\n",
    "            cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb628c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation', 'test'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "599dcd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/singlish/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 742.00it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Armenian-ArmTDP/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 789.74it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_French-ParTUT/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 700.41it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_English-EWT/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 671.63it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Ligurian-GLT/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 694.65it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Gheg-GPS/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 551.52it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Norwegian-Nynorsk/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 680.30it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Albanian-TSA/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 495.78it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Italian-PUD/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 287.52it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Portuguese-Bosque/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 661.67it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Italian-PoSTWITA/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 733.65it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Old_French-SRCMF/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 687.93it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Swiss_German-UZH/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 631.67it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_North_Sami-Giella/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 623.04it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Norwegian-Bokmaal/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 637.04it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_French-ParisStories/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 413.63it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_German-LIT/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 370.78it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Italian-MarkIT/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 592.08it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Chinese-GSDSimp/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 443.26it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Chinese-HK/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 371.90it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Umbrian-IKUVINA/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 345.89it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Guarani-OldTuDeT/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 347.47it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Low_Saxon-LSDC/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 575.75it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_French-Rhapsodie/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 478.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset universal_dependencies/UD_Mbya_Guarani-Thomas to .cache/universal_dependencies/UD_Mbya_Guarani-Thomas/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1298.55it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 380.78it/s]\n",
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset universal_dependencies downloaded and prepared to .cache/universal_dependencies/UD_Mbya_Guarani-Thomas/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 497.78it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Classical_Chinese-Kyoto/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 330.98it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Norwegian-NynorskLIA/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 540.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset universal_dependencies/UD_Komi_Permyak-UH to .cache/universal_dependencies/UD_Komi_Permyak-UH/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 3039.35it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 636.95it/s]\n",
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset universal_dependencies downloaded and prepared to .cache/universal_dependencies/UD_Komi_Permyak-UH/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 629.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset universal_dependencies/UD_Chinese-CFL to .cache/universal_dependencies/UD_Chinese-CFL/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 575.67it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 653.22it/s]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset universal_dependencies downloaded and prepared to .cache/universal_dependencies/UD_Chinese-CFL/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 564.28it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Arabic-NYUAD/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 303.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset universal_dependencies/UD_Portuguese-PUD to .cache/universal_dependencies/UD_Portuguese-PUD/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 966.21it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 893.55it/s]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset universal_dependencies downloaded and prepared to .cache/universal_dependencies/UD_Portuguese-PUD/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 553.34it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Portuguese-PetroGold/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 453.93it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Italian-TWITTIRO/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 545.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset universal_dependencies/UD_Neapolitan-RB to .cache/universal_dependencies/UD_Neapolitan-RB/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 601.25it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 859.84it/s]\n",
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset universal_dependencies downloaded and prepared to .cache/universal_dependencies/UD_Neapolitan-RB/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 558.64it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Turkish_German-SAGT/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 522.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset universal_dependencies/UD_Chinese-PUD to .cache/universal_dependencies/UD_Chinese-PUD/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2136.68it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 728.30it/s]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset universal_dependencies downloaded and prepared to .cache/universal_dependencies/UD_Chinese-PUD/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 648.87it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Maghrebi_Arabic_French-Arabizi/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 551.59it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Portuguese-CINTIL/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 350.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset universal_dependencies/UD_French-PUD to .cache/universal_dependencies/UD_French-PUD/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 633.29it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 748.45it/s]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset universal_dependencies downloaded and prepared to .cache/universal_dependencies/UD_French-PUD/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 575.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset universal_dependencies/UD_South_Levantine_Arabic-MADAR to .cache/universal_dependencies/UD_South_Levantine_Arabic-MADAR/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 3521.67it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 654.44it/s]\n",
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset universal_dependencies downloaded and prepared to .cache/universal_dependencies/UD_South_Levantine_Arabic-MADAR/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 654.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset universal_dependencies/UD_Komi_Zyrian-Lattice to .cache/universal_dependencies/UD_Komi_Zyrian-Lattice/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 745.79it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 145.10it/s]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset universal_dependencies downloaded and prepared to .cache/universal_dependencies/UD_Komi_Zyrian-Lattice/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 657.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset universal_dependencies/UD_Frisian_Dutch-Fame to .cache/universal_dependencies/UD_Frisian_Dutch-Fame/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 3366.22it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 620.64it/s]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset universal_dependencies downloaded and prepared to .cache/universal_dependencies/UD_Frisian_Dutch-Fame/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 557.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset universal_dependencies/UD_Skolt_Sami-Giellagas to .cache/universal_dependencies/UD_Skolt_Sami-Giellagas/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 3184.74it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 612.75it/s]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset universal_dependencies downloaded and prepared to .cache/universal_dependencies/UD_Skolt_Sami-Giellagas/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 599.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset universal_dependencies/UD_Mbya_Guarani-Dooley to .cache/universal_dependencies/UD_Mbya_Guarani-Dooley/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 818.40it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 617.72it/s]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset universal_dependencies downloaded and prepared to .cache/universal_dependencies/UD_Mbya_Guarani-Dooley/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 723.53it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Dutch-Alpino/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 468.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset universal_dependencies/UD_Arabic-PUD to .cache/universal_dependencies/UD_Arabic-PUD/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 620.00it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 774.00it/s]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset universal_dependencies downloaded and prepared to .cache/universal_dependencies/UD_Arabic-PUD/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 582.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset universal_dependencies/UD_Komi_Zyrian-IKDP to .cache/universal_dependencies/UD_Komi_Zyrian-IKDP/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 3472.11it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 682.56it/s]\n",
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset universal_dependencies downloaded and prepared to .cache/universal_dependencies/UD_Komi_Zyrian-IKDP/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 530.52it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Western_Armenian-ArmTDP/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 481.55it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Portuguese-GSD/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 529.65it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Arabic-PADT/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 384.50it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/TwitterAAE/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 509.45it/s]\n"
     ]
    }
   ],
   "source": [
    "counts={\n",
    "    'train':0,'validation':0,'test':0\n",
    "}\n",
    "\n",
    "for lang in all_lang['index']:\n",
    "    dataset = load_dataset(\"scripts/universal_dependencies.py\", lang,\n",
    "            cache_dir=CACHE_DIR)\n",
    "    for key in dataset.keys():\n",
    "        counts[key]+=len(dataset[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c0e02d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 {'train': 251435, 'validation': 31440, 'test': 44324}\n"
     ]
    }
   ],
   "source": [
    "print(len(all_lang),counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b483be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['idx', 'text', 'tokens', 'lemmas', 'upos', 'xpos', 'feats', 'head', 'deprel', 'deps', 'misc'],\n",
      "        num_rows: 1974\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['idx', 'text', 'tokens', 'lemmas', 'upos', 'xpos', 'feats', 'head', 'deprel', 'deps', 'misc'],\n",
      "        num_rows: 249\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['idx', 'text', 'tokens', 'lemmas', 'upos', 'xpos', 'feats', 'head', 'deprel', 'deps', 'misc'],\n",
      "        num_rows: 277\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86537b3a",
   "metadata": {},
   "source": [
    "- parsing use tokens and deprel column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e505170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Մտածում', 'եմ', '՝', 'Ադամի', 'ու', 'Եվայի', 'վտարումը', 'Եդեմական', 'այգուց', '(', 'դրախտից', ')', ',', 'նրանց', 'տեղափոխումն', 'այլ', 'վայր', ',', 'ուր', 'շրջակայքն', 'այլևս', 'բարեկամական', 'չէր', ',', 'այլ', 'խիստ', 'թշնամական', ',', 'ուր', 'իրենց', 'հացը', 'պիտի', 'տանջանքով', 'վաստակեին', ',', 'նույն', 'մոլորակի', 'սահմաններում', 'չէր', ',', 'որ', 'կատարվեց', ':'], ['Եդեմն', 'այլ', 'մոլորակ', 'էր', ',', 'աքսորավայրը', '՝', 'այլ', ',', 'այսինքն', '՝', 'այս', ',', 'ուր', 'այժմ', 'էլ', 'բնակվում', 'ենք', ',', 'բայց', 'միշտ', 'նայում', 'ենք', 'երկինք', '՝', 'բնազդում', 'դրոշմված', 'հիշողությամբ', 'Եդեմը', 'որոնելով', '։'], ['Իսկ', 'այն', 'չկա', ',', 'Տերը', 'պայթեցրել', 'է', 'կամ', 'գուցե', 'ամայացրել', ',', 'բնակության', 'համար', 'անպիտան', 'դարձրել', ',', 'կամ', 'էլ', 'կա', 'ու', 'ախտահանվում', 'է', '՝', 'նոր', 'բնակիչներ', 'ընդունելու', 'համար', '։'], ['Մի', 'խոսքով', '՝', 'մենք', 'դրա', 'հետ', 'էլ', 'գործ', 'չունենք', ',', 'մերը', 'չէ', 'այլևս', ',', 'մերը', 'սա', 'է', '՝', 'դժոխքը', ',', 'որը', ',', 'սակայն', ',', 'հասցրել', 'ենք', 'սիրել', '.', 'դեհ', ',', 'շանը', 'որտեղ', 'էլ', 'կապես', ',', 'կապվում', '-', 'ընտելանում', '-', 'սիրում', 'է', '։'], ['Իրականում', 'հեչ', 'սիրելու', 'բան', 'չի', '.', 'հա', ',', 'էլի', 'որ', '՝', 'կապույտ', 'երկինք', ',', 'ծովեր', ',', 'անտառներ', ',', 'դաշտեր', ':']]\n",
      "\n",
      "[['root', 'aux', 'punct', 'nmod:poss', 'cc', 'conj', 'nsubj', 'amod', 'nmod:npmod', 'punct', 'appos', 'punct', 'punct', 'det:poss', 'conj', 'det', 'nmod:npmod', 'punct', 'advmod', 'nsubj', 'advmod', 'acl:relcl', 'cop', 'punct', 'cc', 'advmod', 'conj', 'punct', 'advmod', 'det:poss', 'obj', 'aux', 'obl', 'conj', 'punct', 'det', 'nmod:poss', 'ccomp', 'cop', 'punct', 'mark', 'csubj', 'punct'], ['nsubj', 'det', 'root', 'cop', 'punct', 'conj', 'punct', 'orphan', 'punct', 'cc', 'punct', 'appos', 'punct', 'advmod', 'advmod', 'advmod', 'acl:relcl', 'aux', 'punct', 'cc', 'advmod', 'conj', 'aux', 'obl', 'punct', 'obl', 'acl', 'obl', 'obj', 'advcl', 'punct'], ['cc', 'nsubj', 'root', 'punct', 'nsubj', 'parataxis', 'aux', 'cc', 'discourse', 'conj', 'punct', 'obl', 'case', 'xcomp', 'conj', 'punct', 'cc', 'fixed', 'conj', 'cc', 'conj', 'aux', 'punct', 'amod', 'obj', 'obl', 'case', 'punct'], ['nummod', 'parataxis', 'punct', 'nsubj', 'obl', 'case', 'advmod:emph', 'compound:lvc', 'root', 'punct', 'conj', 'cop', 'advmod:emph', 'punct', 'nsubj', 'conj', 'cop', 'punct', 'appos', 'punct', 'nsubj', 'punct', 'discourse', 'punct', 'acl:relcl', 'aux', 'xcomp', 'punct', 'discourse', 'punct', 'obj', 'advmod', 'advmod', 'parataxis', 'punct', 'conj', 'punct', 'conj', 'punct', 'conj', 'aux', 'punct'], ['advmod', 'advmod', 'nmod:poss', 'root', 'cop', 'punct', 'discourse', 'punct', 'discourse', 'fixed', 'punct', 'amod', 'parataxis', 'punct', 'conj', 'punct', 'conj', 'punct', 'conj', 'punct']]\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train']['tokens'][:5])\n",
    "print()\n",
    "print(dataset['train']['deprel'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90899dbf",
   "metadata": {},
   "source": [
    "### 2. pos tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7d3a943",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_langs=[\"UD_Armenian-ArmTDP\", \"UD_Norwegian-Nynorsk\", \"UD_Portuguese-Bosque\", \"UD_Italian-PoSTWITA\", \"UD_Old_French-SRCMF\", \"UD_North_Sami-Giella\", \"UD_Norwegian-Bokmaal\", \"UD_French-ParisStories\", \"UD_Italian-MarkIT\", \"UD_Chinese-GSDSimp\", \"UD_English-EWT\", \"UD_French-Rhapsodie\", \"UD_French-ParTUT\", \"UD_Classical_Chinese-Kyoto\", \"UD_Norwegian-NynorskLIA\", \"UD_Arabic-NYUAD\", \"UD_Portuguese-PetroGold\", \"UD_Italian-TWITTIRO\", \"UD_Turkish_German-SAGT\", \"UD_Maghrebi_Arabic_French-Arabizi\", \"UD_Portuguese-CINTIL\", \"UD_Ligurian-GLT\", \"UD_Dutch-Alpino\", \"UD_Western_Armenian-ArmTDP\", \"UD_Portuguese-GSD\", \"singlish\", \"UD_Arabic-PADT\", \"UD_French-GSD\", \"UD_Catalan-AnCora\", \"UD_Estonian-EDT\", \"UD_Finnish-TDT\", \"UD_Spanish-AnCora\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e16bda87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UD_Armenian-ArmTDP', 'UD_Norwegian-Nynorsk', 'UD_Portuguese-Bosque', 'UD_Italian-PoSTWITA', 'UD_Old_French-SRCMF', 'UD_North_Sami-Giella', 'UD_Norwegian-Bokmaal', 'UD_French-ParisStories', 'UD_Italian-MarkIT', 'UD_Chinese-GSDSimp', 'UD_English-EWT', 'UD_French-Rhapsodie', 'UD_French-ParTUT', 'UD_Classical_Chinese-Kyoto', 'UD_Norwegian-NynorskLIA', 'UD_Arabic-NYUAD', 'UD_Portuguese-PetroGold', 'UD_Italian-TWITTIRO', 'UD_Turkish_German-SAGT', 'UD_Maghrebi_Arabic_French-Arabizi', 'UD_Portuguese-CINTIL', 'UD_Ligurian-GLT', 'UD_Dutch-Alpino', 'UD_Western_Armenian-ArmTDP', 'UD_Portuguese-GSD', 'singlish', 'UD_Arabic-PADT', 'UD_French-GSD', 'UD_Catalan-AnCora', 'UD_Estonian-EDT', 'UD_Finnish-TDT', 'UD_Spanish-AnCora']\n"
     ]
    }
   ],
   "source": [
    "print(train_langs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97375a95",
   "metadata": {},
   "source": [
    "- we finetune each lang where train split available\n",
    "- if train split not available, we perform zero-shot from UD_English-EWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40029288",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('metadata/pos_metadata.json')\n",
    "metadata = json.load(f)\n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18ddb29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lang</th>\n",
       "      <th>code</th>\n",
       "      <th>desc</th>\n",
       "      <th>langgroup</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>singlish</td>\n",
       "      <td>singlish</td>\n",
       "      <td>eng-sing</td>\n",
       "      <td></td>\n",
       "      <td>English</td>\n",
       "      <td>[dev, test, train]</td>\n",
       "      <td>ud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROci</td>\n",
       "      <td>occitan</td>\n",
       "      <td>ROci</td>\n",
       "      <td></td>\n",
       "      <td>French-occ</td>\n",
       "      <td>[test]</td>\n",
       "      <td>noisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UD_Armenian-ArmTDP</td>\n",
       "      <td>Armenian</td>\n",
       "      <td>hye-east</td>\n",
       "      <td></td>\n",
       "      <td>Armenian</td>\n",
       "      <td>[train, test, dev]</td>\n",
       "      <td>ud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UD_French-ParTUT</td>\n",
       "      <td>French</td>\n",
       "      <td>fre-multigenre</td>\n",
       "      <td></td>\n",
       "      <td>French</td>\n",
       "      <td>[train, dev, test]</td>\n",
       "      <td>ud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UD_English-EWT</td>\n",
       "      <td>English</td>\n",
       "      <td>eng</td>\n",
       "      <td></td>\n",
       "      <td>English</td>\n",
       "      <td>[dev, test, train]</td>\n",
       "      <td>ud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UD_Ligurian-GLT</td>\n",
       "      <td>Ligurian</td>\n",
       "      <td>lij</td>\n",
       "      <td></td>\n",
       "      <td>Italian</td>\n",
       "      <td>[train, test]</td>\n",
       "      <td>ud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UD_Gheg-GPS</td>\n",
       "      <td>Gheg</td>\n",
       "      <td>aln</td>\n",
       "      <td></td>\n",
       "      <td>Albanian</td>\n",
       "      <td>[test]</td>\n",
       "      <td>ud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UD_Norwegian-Nynorsk</td>\n",
       "      <td>Norwegian</td>\n",
       "      <td>nor-nynorsk</td>\n",
       "      <td></td>\n",
       "      <td>Norwegian</td>\n",
       "      <td>[test, dev, train]</td>\n",
       "      <td>ud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UD_Albanian-TSA</td>\n",
       "      <td>Albanian</td>\n",
       "      <td>alb</td>\n",
       "      <td></td>\n",
       "      <td>Albanian</td>\n",
       "      <td>[test]</td>\n",
       "      <td>ud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UD_Italian-PUD</td>\n",
       "      <td>Italian</td>\n",
       "      <td>ita-trans</td>\n",
       "      <td></td>\n",
       "      <td>Italian</td>\n",
       "      <td>[test]</td>\n",
       "      <td>ud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  index       lang            code desc   langgroup  \\\n",
       "0              singlish   singlish        eng-sing          English   \n",
       "1                  ROci    occitan            ROci       French-occ   \n",
       "2    UD_Armenian-ArmTDP   Armenian        hye-east         Armenian   \n",
       "3      UD_French-ParTUT     French  fre-multigenre           French   \n",
       "4        UD_English-EWT    English             eng          English   \n",
       "5       UD_Ligurian-GLT   Ligurian             lij          Italian   \n",
       "6           UD_Gheg-GPS       Gheg             aln         Albanian   \n",
       "7  UD_Norwegian-Nynorsk  Norwegian     nor-nynorsk        Norwegian   \n",
       "8       UD_Albanian-TSA   Albanian             alb         Albanian   \n",
       "9        UD_Italian-PUD    Italian       ita-trans          Italian   \n",
       "\n",
       "                split dataset  \n",
       "0  [dev, test, train]      ud  \n",
       "1              [test]   noisy  \n",
       "2  [train, test, dev]      ud  \n",
       "3  [train, dev, test]      ud  \n",
       "4  [dev, test, train]      ud  \n",
       "5       [train, test]      ud  \n",
       "6              [test]      ud  \n",
       "7  [test, dev, train]      ud  \n",
       "8              [test]      ud  \n",
       "9              [test]      ud  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lang=pd.DataFrame(metadata).T\n",
    "all_lang.reset_index(level=0, inplace=True)\n",
    "all_lang.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72581780",
   "metadata": {},
   "source": [
    "#### use different dataset loading script depending on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5260ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/singlish/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 569.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['idx', 'text', 'tokens', 'lemmas', 'upos', 'xpos', 'feats', 'head', 'deprel', 'deps', 'misc'],\n",
      "        num_rows: 2465\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['idx', 'text', 'tokens', 'lemmas', 'upos', 'xpos', 'feats', 'head', 'deprel', 'deps', 'misc'],\n",
      "        num_rows: 286\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['idx', 'text', 'tokens', 'lemmas', 'upos', 'xpos', 'feats', 'head', 'deprel', 'deps', 'misc'],\n",
      "        num_rows: 299\n",
      "    })\n",
      "})\n",
      "[['bt', 'still', 'okie', 'la', 'if', 'go', 'hong', 'kong', '.', '.'], ['Semb', 'Corp', '3.28', 'coming', '.']]\n",
      "[[10, 14, 6, 15, 5, 16, 10, 10, 1, 1], [10, 10, 3, 16, 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lang='singlish' ## metadata[lang]['dataset']=='ud':\n",
    "script=\"scripts/universal_dependencies.py\"\n",
    "predict_dataset = load_dataset(script, lang, cache_dir=CACHE_DIR)\n",
    "print(predict_dataset)\n",
    "print(predict_dataset['test']['tokens'][:2])\n",
    "print(predict_dataset['test']['upos'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "808d812d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/singlish/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 558.77it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Armenian-ArmTDP/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 760.43it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_French-ParTUT/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 506.07it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_English-EWT/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 445.95it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Ligurian-GLT/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 609.02it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Gheg-GPS/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 370.26it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Norwegian-Nynorsk/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 453.59it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Albanian-TSA/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 347.73it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Italian-PUD/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 413.76it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Portuguese-Bosque/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 455.24it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Italian-PoSTWITA/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 530.32it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Old_French-SRCMF/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 417.84it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Swiss_German-UZH/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 350.02it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_North_Sami-Giella/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 503.25it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Norwegian-Bokmaal/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 489.70it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_French-ParisStories/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 509.43it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_German-LIT/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 338.41it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Italian-MarkIT/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 519.38it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Chinese-GSDSimp/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 525.67it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Chinese-HK/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 388.47it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Umbrian-IKUVINA/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 457.24it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Guarani-OldTuDeT/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 447.82it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Low_Saxon-LSDC/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 455.95it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_French-Rhapsodie/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 541.81it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Mbya_Guarani-Thomas/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 362.83it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Classical_Chinese-Kyoto/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 293.34it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Norwegian-NynorskLIA/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 542.79it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Komi_Permyak-UH/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 375.53it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Chinese-CFL/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 370.49it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Arabic-NYUAD/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 319.45it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Portuguese-PUD/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 395.24it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Portuguese-PetroGold/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 439.16it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Italian-TWITTIRO/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 331.24it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Neapolitan-RB/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 426.47it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Turkish_German-SAGT/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 547.65it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Chinese-PUD/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 383.57it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Maghrebi_Arabic_French-Arabizi/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 505.32it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Portuguese-CINTIL/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 367.60it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_French-PUD/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 373.96it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_South_Levantine_Arabic-MADAR/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 400.99it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Komi_Zyrian-Lattice/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 351.11it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Frisian_Dutch-Fame/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 394.94it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Skolt_Sami-Giellagas/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 379.37it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Mbya_Guarani-Dooley/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 369.44it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Dutch-Alpino/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 489.15it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Arabic-PUD/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 375.97it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Komi_Zyrian-IKDP/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 396.96it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Western_Armenian-ArmTDP/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 500.10it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Portuguese-GSD/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 474.68it/s]\n",
      "Reusing dataset universal_dependencies (.cache/universal_dependencies/UD_Arabic-PADT/2.7.0/965e769bf67498e9a458ccb7524974ab67c0b8e377537a4a33c2d025c8fc4fe6)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 475.29it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "BuilderConfig UD_Spanish-AnCora not found. Available: ['UD_Armenian-ArmTDP', 'UD_Gheg-GPS', 'UD_Norwegian-Nynorsk', 'UD_Albanian-TSA', 'UD_Italian-PUD', 'UD_Portuguese-Bosque', 'UD_Italian-PoSTWITA', 'UD_Old_French-SRCMF', 'UD_Swiss_German-UZH', 'UD_North_Sami-Giella', 'UD_Norwegian-Bokmaal', 'UD_French-ParisStories', 'UD_German-LIT', 'UD_Italian-MarkIT', 'UD_Chinese-GSDSimp', 'UD_Chinese-HK', 'UD_Umbrian-IKUVINA', 'UD_Guarani-OldTuDeT', 'UD_Low_Saxon-LSDC', 'UD_French-Rhapsodie', 'UD_Mbya_Guarani-Thomas', 'UD_French-ParTUT', 'UD_Classical_Chinese-Kyoto', 'UD_Norwegian-NynorskLIA', 'UD_Komi_Permyak-UH', 'UD_Chinese-CFL', 'UD_Arabic-NYUAD', 'UD_Portuguese-PUD', 'UD_Portuguese-PetroGold', 'UD_Italian-TWITTIRO', 'UD_Neapolitan-RB', 'UD_Turkish_German-SAGT', 'UD_Chinese-PUD', 'UD_Maghrebi_Arabic_French-Arabizi', 'UD_Portuguese-CINTIL', 'UD_French-PUD', 'UD_South_Levantine_Arabic-MADAR', 'UD_Komi_Zyrian-Lattice', 'UD_Frisian_Dutch-Fame', 'UD_Skolt_Sami-Giellagas', 'UD_Mbya_Guarani-Dooley', 'UD_Ligurian-GLT', 'UD_Dutch-Alpino', 'UD_Arabic-PUD', 'UD_Komi_Zyrian-IKDP', 'UD_Western_Armenian-ArmTDP', 'UD_Portuguese-GSD', 'singlish', 'UD_Arabic-PADT', 'TwitterAAE', 'UD_English-EWT']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m ud_ones\u001b[38;5;241m=\u001b[39mall_lang[all_lang[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mud\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lang \u001b[38;5;129;01min\u001b[39;00m ud_ones[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m----> 7\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscript\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCACHE_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     10\u001b[0m         counts[key]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataset[key])\n",
      "File \u001b[0;32m~/Projects/neg_inf/vnv/vnv-adp-l/lib/python3.9/site-packages/datasets/load.py:1723\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, **config_kwargs)\u001b[0m\n\u001b[1;32m   1720\u001b[0m ignore_verifications \u001b[38;5;241m=\u001b[39m ignore_verifications \u001b[38;5;129;01mor\u001b[39;00m save_infos\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 1723\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1733\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1734\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1735\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m~/Projects/neg_inf/vnv/vnv-adp-l/lib/python3.9/site-packages/datasets/load.py:1526\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, use_auth_token, **config_kwargs)\u001b[0m\n\u001b[1;32m   1523\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;66;03m# Instantiate the dataset builder\u001b[39;00m\n\u001b[0;32m-> 1526\u001b[0m builder_instance: DatasetBuilder \u001b[38;5;241m=\u001b[39m \u001b[43mbuilder_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mhash\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbuilder_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance\n",
      "File \u001b[0;32m~/Projects/neg_inf/vnv/vnv-adp-l/lib/python3.9/site-packages/datasets/builder.py:1154\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder.__init__\u001b[0;34m(self, writer_batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, writer_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1154\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;66;03m# Batch size used by the ArrowWriter\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;66;03m# It defines the number of samples that are kept in memory before writing them\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;66;03m# and also the length of the arrow chunks\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;66;03m# None means that the ArrowWriter will use its default value\u001b[39;00m\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer_batch_size \u001b[38;5;241m=\u001b[39m writer_batch_size \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDEFAULT_WRITER_BATCH_SIZE\n",
      "File \u001b[0;32m~/Projects/neg_inf/vnv/vnv-adp-l/lib/python3.9/site-packages/datasets/builder.py:297\u001b[0m, in \u001b[0;36mDatasetBuilder.__init__\u001b[0;34m(self, cache_dir, config_name, hash, base_path, info, features, use_auth_token, repo_id, data_files, data_dir, name, **config_kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    296\u001b[0m     config_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data_dir\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_builder_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# prepare info: DatasetInfo are a standardized dataclass across all datasets\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# Prefill datasetinfo\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Projects/neg_inf/vnv/vnv-adp-l/lib/python3.9/site-packages/datasets/builder.py:434\u001b[0m, in \u001b[0;36mDatasetBuilder._create_builder_config\u001b[0;34m(self, name, custom_features, **config_kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m     builder_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder_configs\u001b[38;5;241m.\u001b[39mget(name)\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m builder_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBUILDER_CONFIGS:\n\u001b[0;32m--> 434\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuilderConfig \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found. Available: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder_configs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# if not using an existing config, then create a new config on the fly with config_kwargs\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m builder_config:\n",
      "\u001b[0;31mValueError\u001b[0m: BuilderConfig UD_Spanish-AnCora not found. Available: ['UD_Armenian-ArmTDP', 'UD_Gheg-GPS', 'UD_Norwegian-Nynorsk', 'UD_Albanian-TSA', 'UD_Italian-PUD', 'UD_Portuguese-Bosque', 'UD_Italian-PoSTWITA', 'UD_Old_French-SRCMF', 'UD_Swiss_German-UZH', 'UD_North_Sami-Giella', 'UD_Norwegian-Bokmaal', 'UD_French-ParisStories', 'UD_German-LIT', 'UD_Italian-MarkIT', 'UD_Chinese-GSDSimp', 'UD_Chinese-HK', 'UD_Umbrian-IKUVINA', 'UD_Guarani-OldTuDeT', 'UD_Low_Saxon-LSDC', 'UD_French-Rhapsodie', 'UD_Mbya_Guarani-Thomas', 'UD_French-ParTUT', 'UD_Classical_Chinese-Kyoto', 'UD_Norwegian-NynorskLIA', 'UD_Komi_Permyak-UH', 'UD_Chinese-CFL', 'UD_Arabic-NYUAD', 'UD_Portuguese-PUD', 'UD_Portuguese-PetroGold', 'UD_Italian-TWITTIRO', 'UD_Neapolitan-RB', 'UD_Turkish_German-SAGT', 'UD_Chinese-PUD', 'UD_Maghrebi_Arabic_French-Arabizi', 'UD_Portuguese-CINTIL', 'UD_French-PUD', 'UD_South_Levantine_Arabic-MADAR', 'UD_Komi_Zyrian-Lattice', 'UD_Frisian_Dutch-Fame', 'UD_Skolt_Sami-Giellagas', 'UD_Mbya_Guarani-Dooley', 'UD_Ligurian-GLT', 'UD_Dutch-Alpino', 'UD_Arabic-PUD', 'UD_Komi_Zyrian-IKDP', 'UD_Western_Armenian-ArmTDP', 'UD_Portuguese-GSD', 'singlish', 'UD_Arabic-PADT', 'TwitterAAE', 'UD_English-EWT']"
     ]
    }
   ],
   "source": [
    "counts={\n",
    "    'train':0,'validation':0,'test':0\n",
    "}\n",
    "script=\"scripts/universal_dependencies.py\"\n",
    "ud_ones=all_lang[all_lang['dataset']=='ud']\n",
    "for lang in ud_ones['index']:\n",
    "    dataset = load_dataset(script, lang,\n",
    "            cache_dir=CACHE_DIR)\n",
    "    for key in dataset.keys():\n",
    "        counts[key]+=len(dataset[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a807d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a0cffd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration ROci-data_dir=data%2Fpos_tagging\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset noisy_dialect/ROci to .cache/noisy_dialect/ROci-data_dir=data%2Fpos_tagging/1.1.0/a0e4190d7e72716271d4c2496d5dcf596262a4082468db5160758db6f295efe5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset noisy_dialect downloaded and prepared to .cache/noisy_dialect/ROci-data_dir=data%2Fpos_tagging/1.1.0/a0e4190d7e72716271d4c2496d5dcf596262a4082468db5160758db6f295efe5. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 828.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['id', 'tokens', 'upos'],\n",
      "        num_rows: 874\n",
      "    })\n",
      "})\n",
      "[['Puei', ',', 'sabètz', ',', 'se', 'fins_a', 'cinc', 'ans', 'avètz', 'gaire', 'de', 'sovenirs', ',', 'après', 'un', 'pichòt', 'saup', 'chifrar', 'e', 'pòu', 'jutjar', 'de', 'son', 'sicut', '.'], ['Me', 'rèstan', 'pasmens', 'quauquei', 'sovenirs', \"d'\", 'avans', 'cinc', 'ans', '.']]\n",
      "[[14, 1, 16, 1, 5, 2, 3, 0, 16, 14, 2, 0, 1, 2, 8, 0, 16, 16, 9, 16, 16, 2, 8, 0, 1], [11, 16, 14, 11, 0, 2, 2, 3, 0, 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lang='ROci' ## metadata[lang]['dataset']=='noisy':\n",
    "script=\"scripts/pos_tagging/noisy_dialect.py\"\n",
    "data_dir=\"data/pos_tagging\"\n",
    "predict_dataset = load_dataset(script, lang, data_dir=data_dir,cache_dir=CACHE_DIR)\n",
    "print(predict_dataset)\n",
    "print(predict_dataset['test']['tokens'][:2])\n",
    "print(predict_dataset['test']['upos'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e34c97ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration ROci-data_dir=data%2Fpos_tagging\n",
      "Reusing dataset noisy_dialect (.cache/noisy_dialect/ROci-data_dir=data%2Fpos_tagging/1.1.0/a0e4190d7e72716271d4c2496d5dcf596262a4082468db5160758db6f295efe5)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 479.57it/s]\n",
      "Using custom data configuration dar-egy-data_dir=data%2Fpos_tagging\n",
      "Reusing dataset noisy_dialect (.cache/noisy_dialect/dar-egy-data_dir=data%2Fpos_tagging/1.1.0/a0e4190d7e72716271d4c2496d5dcf596262a4082468db5160758db6f295efe5)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 635.40it/s]\n",
      "Using custom data configuration dar-glf-data_dir=data%2Fpos_tagging\n",
      "Reusing dataset noisy_dialect (.cache/noisy_dialect/dar-glf-data_dir=data%2Fpos_tagging/1.1.0/a0e4190d7e72716271d4c2496d5dcf596262a4082468db5160758db6f295efe5)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 876.55it/s]\n",
      "Using custom data configuration dar-mgr-data_dir=data%2Fpos_tagging\n",
      "Reusing dataset noisy_dialect (.cache/noisy_dialect/dar-mgr-data_dir=data%2Fpos_tagging/1.1.0/a0e4190d7e72716271d4c2496d5dcf596262a4082468db5160758db6f295efe5)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 863.74it/s]\n",
      "Using custom data configuration dar-lev-data_dir=data%2Fpos_tagging\n",
      "Reusing dataset noisy_dialect (.cache/noisy_dialect/dar-lev-data_dir=data%2Fpos_tagging/1.1.0/a0e4190d7e72716271d4c2496d5dcf596262a4082468db5160758db6f295efe5)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 800.59it/s]\n",
      "Using custom data configuration murre-HÄM-data_dir=data%2Fpos_tagging\n",
      "Reusing dataset noisy_dialect (.cache/noisy_dialect/murre-HÄM-data_dir=data%2Fpos_tagging/1.1.0/a0e4190d7e72716271d4c2496d5dcf596262a4082468db5160758db6f295efe5)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 662.71it/s]\n",
      "Using custom data configuration murre-KAA-data_dir=data%2Fpos_tagging\n",
      "Reusing dataset noisy_dialect (.cache/noisy_dialect/murre-KAA-data_dir=data%2Fpos_tagging/1.1.0/a0e4190d7e72716271d4c2496d5dcf596262a4082468db5160758db6f295efe5)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 807.06it/s]\n",
      "Using custom data configuration murre-LOU-data_dir=data%2Fpos_tagging\n",
      "Reusing dataset noisy_dialect (.cache/noisy_dialect/murre-LOU-data_dir=data%2Fpos_tagging/1.1.0/a0e4190d7e72716271d4c2496d5dcf596262a4082468db5160758db6f295efe5)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 720.67it/s]\n",
      "Using custom data configuration murre-LVÄ-data_dir=data%2Fpos_tagging\n",
      "Reusing dataset noisy_dialect (.cache/noisy_dialect/murre-LVÄ-data_dir=data%2Fpos_tagging/1.1.0/a0e4190d7e72716271d4c2496d5dcf596262a4082468db5160758db6f295efe5)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 614.28it/s]\n",
      "Using custom data configuration murre-POH-data_dir=data%2Fpos_tagging\n",
      "Reusing dataset noisy_dialect (.cache/noisy_dialect/murre-POH-data_dir=data%2Fpos_tagging/1.1.0/a0e4190d7e72716271d4c2496d5dcf596262a4082468db5160758db6f295efe5)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 716.85it/s]\n",
      "Using custom data configuration murre-SAV-data_dir=data%2Fpos_tagging\n",
      "Reusing dataset noisy_dialect (.cache/noisy_dialect/murre-SAV-data_dir=data%2Fpos_tagging/1.1.0/a0e4190d7e72716271d4c2496d5dcf596262a4082468db5160758db6f295efe5)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 755.87it/s]\n"
     ]
    }
   ],
   "source": [
    "script=\"scripts/pos_tagging/noisy_dialect.py\"\n",
    "ud_ones=all_lang[all_lang['dataset']=='noisy']\n",
    "for lang in ud_ones['index']:\n",
    "    dataset = load_dataset(script, lang, data_dir=data_dir,\n",
    "            cache_dir=CACHE_DIR)\n",
    "    for key in dataset.keys():\n",
    "        counts[key]+=len(dataset[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4ba17625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 {'train': 251435, 'validation': 31440, 'test': 100604}\n"
     ]
    }
   ],
   "source": [
    "print(len(all_lang),counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3043579f",
   "metadata": {},
   "source": [
    "### 3. ner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b300c9",
   "metadata": {},
   "source": [
    "- we train one language/dialect per language/dialect group and evaluate on the whole group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "868e8236",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiann_train_langs=[\"ar\", \"az\", \"ku\", \"tr\", \"hsb\", \"nl\", \"fr\", \"zh\", \"en\", \"mhr\", \"it\", \"de\", \"pa\", \"es\", \"hr\", \"lv\", \"hi\", \"ro\", \"el\", \"bn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2988a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ar', 'az', 'ku', 'tr', 'hsb', 'nl', 'fr', 'zh', 'en', 'mhr', 'it', 'de', 'pa', 'es', 'hr', 'lv', 'hi', 'ro', 'el', 'bn']\n"
     ]
    }
   ],
   "source": [
    "print(wikiann_train_langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5b18ef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "norwegian_train_langs=[\"bokmaal\" ,\"nynorsk\" ,\"samnorsk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45b03120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bokmaal', 'nynorsk', 'samnorsk']\n"
     ]
    }
   ],
   "source": [
    "print(norwegian_train_langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b93e4d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('metadata/ner_metadata.json')\n",
    "metadata = json.load(f)\n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf280b0",
   "metadata": {},
   "source": [
    "- langgroup corresponds to the training language per group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "039ad1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>code</th>\n",
       "      <th>langgroup</th>\n",
       "      <th>huggingface</th>\n",
       "      <th>dataset</th>\n",
       "      <th>region</th>\n",
       "      <th>train_lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ar</th>\n",
       "      <td>arabic</td>\n",
       "      <td>ar</td>\n",
       "      <td>arabic</td>\n",
       "      <td>True</td>\n",
       "      <td>wikiann</td>\n",
       "      <td>arabic</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arz</th>\n",
       "      <td>egyptian arabic</td>\n",
       "      <td>arz</td>\n",
       "      <td>arabic</td>\n",
       "      <td>True</td>\n",
       "      <td>wikiann</td>\n",
       "      <td>arabic</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kab</th>\n",
       "      <td>kabyle</td>\n",
       "      <td>kab</td>\n",
       "      <td>arabic</td>\n",
       "      <td>False</td>\n",
       "      <td>wikiann</td>\n",
       "      <td>arabic</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kbd</th>\n",
       "      <td>kabardian</td>\n",
       "      <td>kbd</td>\n",
       "      <td>adyghe</td>\n",
       "      <td>False</td>\n",
       "      <td>wikiann</td>\n",
       "      <td>adyghe</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ady</th>\n",
       "      <td>adyghe</td>\n",
       "      <td>ady</td>\n",
       "      <td>adyghe</td>\n",
       "      <td>False</td>\n",
       "      <td>wikiann</td>\n",
       "      <td>adyghe</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as</th>\n",
       "      <td>assamese</td>\n",
       "      <td>as</td>\n",
       "      <td>bangla</td>\n",
       "      <td>True</td>\n",
       "      <td>wikiann</td>\n",
       "      <td>bangla</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bn</th>\n",
       "      <td>bangla</td>\n",
       "      <td>bn</td>\n",
       "      <td>bangla</td>\n",
       "      <td>True</td>\n",
       "      <td>wikiann</td>\n",
       "      <td>bangla</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nob</th>\n",
       "      <td>bokmaal</td>\n",
       "      <td>nob</td>\n",
       "      <td>norwegian</td>\n",
       "      <td>True</td>\n",
       "      <td>norwegian_ner</td>\n",
       "      <td>norwegian</td>\n",
       "      <td>bokmaal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nno</th>\n",
       "      <td>nynorsk</td>\n",
       "      <td>nno</td>\n",
       "      <td>norwegian</td>\n",
       "      <td>True</td>\n",
       "      <td>norwegian_ner</td>\n",
       "      <td>norwegian</td>\n",
       "      <td>nynorsk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samnorsk</th>\n",
       "      <td>samnorsk</td>\n",
       "      <td>samnorsk</td>\n",
       "      <td>norwegian</td>\n",
       "      <td>True</td>\n",
       "      <td>norwegian_ner</td>\n",
       "      <td>norwegian</td>\n",
       "      <td>samnorsk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     lang      code  langgroup huggingface        dataset  \\\n",
       "ar                 arabic        ar     arabic        True        wikiann   \n",
       "arz       egyptian arabic       arz     arabic        True        wikiann   \n",
       "kab                kabyle       kab     arabic       False        wikiann   \n",
       "kbd             kabardian       kbd     adyghe       False        wikiann   \n",
       "ady                adyghe       ady     adyghe       False        wikiann   \n",
       "...                   ...       ...        ...         ...            ...   \n",
       "as               assamese        as     bangla        True        wikiann   \n",
       "bn                 bangla        bn     bangla        True        wikiann   \n",
       "nob               bokmaal       nob  norwegian        True  norwegian_ner   \n",
       "nno               nynorsk       nno  norwegian        True  norwegian_ner   \n",
       "samnorsk         samnorsk  samnorsk  norwegian        True  norwegian_ner   \n",
       "\n",
       "             region train_lang  \n",
       "ar           arabic         ar  \n",
       "arz          arabic         ar  \n",
       "kab          arabic         ar  \n",
       "kbd          adyghe         en  \n",
       "ady          adyghe         en  \n",
       "...             ...        ...  \n",
       "as           bangla         bn  \n",
       "bn           bangla         bn  \n",
       "nob       norwegian    bokmaal  \n",
       "nno       norwegian    nynorsk  \n",
       "samnorsk  norwegian   samnorsk  \n",
       "\n",
       "[89 rows x 7 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lang=pd.DataFrame(metadata).T\n",
    "all_lang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1f3d3b",
   "metadata": {},
   "source": [
    "- different dataset loading script for different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7dec9f23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikiann (.cache/wikiann/ar/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 701.94it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/arz/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 909.04it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/az/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 876.19it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/ckb/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 753.42it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/ku/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 726.87it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/tr/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 742.22it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/crh/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 817.66it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/hsb/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 726.41it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/frr/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 840.09it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/fy/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 736.23it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/lb/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 851.52it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/li/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 918.53it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/nl/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 665.94it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/vls/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 988.76it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/zea/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1060.42it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/ksh/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 800.24it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/wa/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 944.52it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/fr/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 774.38it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/hak/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 698.78it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/wuu/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 892.03it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/zh/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 681.19it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/zh-classical/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 855.63it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/zh-min-nan/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 874.42it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/zh-yue/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 733.31it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/simple/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 776.44it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/ang/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 955.06it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/en/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 745.70it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/mhr/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 902.52it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/lij/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 741.87it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/nap/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 960.31it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/scn/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 960.53it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/lmo/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 896.09it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/co/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 862.55it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/eml/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 792.18it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/fur/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 921.15it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/it/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 681.52it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/rm/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 863.86it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/vec/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1050.41it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/nds/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 773.62it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/pdc/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 992.97it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/de/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 716.69it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/bar/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 964.65it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/als/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 965.54it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/pnb/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1010.51it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/pa/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 994.93it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/es/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 825.98it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/ext/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 955.42it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/gl/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 801.71it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/mwl/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 931.38it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/sh/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 791.78it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/hr/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 716.00it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/sr/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 752.48it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/bs/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 738.35it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/oc/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 975.27it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/pms/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1039.22it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/lv/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 828.48it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/hi/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 757.55it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/ro/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 758.33it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/el/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 723.20it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/as/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 987.82it/s]\n",
      "Reusing dataset wikiann (.cache/wikiann/bn/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1041.63it/s]\n"
     ]
    }
   ],
   "source": [
    "counts={\n",
    "    'train':0,'validation':0,'test':0\n",
    "}\n",
    "script=\"wikiann\"\n",
    "ud_ones=all_lang[(all_lang['huggingface']==True) & (all_lang['dataset']=='wikiann')]\n",
    "for lang in ud_ones['code']:\n",
    "    dataset = load_dataset(script, lang,\n",
    "            cache_dir=CACHE_DIR)\n",
    "    for key in dataset.keys():\n",
    "        counts[key]+=len(dataset[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b564a8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/kab to .cache/wikiann_og/kab/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n",
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f95100a45b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/kab/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 834.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/kbd to .cache/wikiann_og/kbd/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n",
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f950968e400>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/kbd/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 883.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/ady to .cache/wikiann_og/ady/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n",
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f950968e250>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/ady/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 753.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/azb to .cache/wikiann_og/azb/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n",
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f9509686c70>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/azb/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 599.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/dsb to .cache/wikiann_og/dsb/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f95100a3190>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/dsb/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 728.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/stq to .cache/wikiann_og/stq/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n",
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f95100c5730>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/stq/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 618.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/nrm to .cache/wikiann_og/nrm/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n",
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f95100c5c70>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/nrm/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 633.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/jam to .cache/wikiann_og/jam/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n",
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f9508d156d0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/jam/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 687.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/koi to .cache/wikiann_og/koi/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n",
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f95095e01f0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/koi/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 667.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/kv to .cache/wikiann_og/kv/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f95100c5520>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/kv/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1026.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/mrj to .cache/wikiann_og/mrj/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f95096a3610>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/mrj/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 927.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/sc to .cache/wikiann_og/sc/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n",
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f9508de3be0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/sc/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1119.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/roa-tara to .cache/wikiann_og/roa-tara/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n",
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f95335e6df0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/roa-tara/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 791.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/kl to .cache/wikiann_og/kl/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n",
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f9533f24cd0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/kl/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 907.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/ik to .cache/wikiann_og/ik/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n",
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f9533fc2610>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/ik/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 877.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/nds-nl to .cache/wikiann_og/nds-nl/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n",
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f950b8d3ca0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/nds-nl/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 857.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/pfl to .cache/wikiann_og/pfl/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f953353d9d0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/pfl/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 766.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/nso to .cache/wikiann_og/nso/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n",
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f95100a40a0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/nso/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1142.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/st to .cache/wikiann_og/st/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n",
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f953301c7c0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/st/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 903.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/frp to .cache/wikiann_og/frp/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n",
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f9533a15580>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/frp/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 868.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/ltg to .cache/wikiann_og/ltg/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f953301c460>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/ltg/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 736.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/hif to .cache/wikiann_og/hif/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n",
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f95100a3130>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/hif/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 761.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/mo to .cache/wikiann_og/mo/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n",
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f95096ad1f0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/mo/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 864.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/pnt to .cache/wikiann_og/pnt/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n",
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f9533155670>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/pnt/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 797.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/roa-rup to .cache/wikiann_og/roa-rup/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<datasets.download.download_manager.ArchiveIterable object at 0x7f94e0236be0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/roa-rup/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 865.70it/s]\n"
     ]
    }
   ],
   "source": [
    "script=\"scripts/ner/wikiann_og.py\"\n",
    "ud_ones=all_lang[(all_lang['huggingface']==False) & (all_lang['dataset']=='wikiann')]\n",
    "for lang in ud_ones['code']:\n",
    "    dataset = load_dataset(script, lang,\n",
    "            cache_dir=CACHE_DIR)\n",
    "    for key in dataset.keys():\n",
    "        counts[key]+=len(dataset[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6a896ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>code</th>\n",
       "      <th>langgroup</th>\n",
       "      <th>huggingface</th>\n",
       "      <th>dataset</th>\n",
       "      <th>region</th>\n",
       "      <th>train_lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nob</th>\n",
       "      <td>bokmaal</td>\n",
       "      <td>nob</td>\n",
       "      <td>norwegian</td>\n",
       "      <td>True</td>\n",
       "      <td>norwegian_ner</td>\n",
       "      <td>norwegian</td>\n",
       "      <td>bokmaal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nno</th>\n",
       "      <td>nynorsk</td>\n",
       "      <td>nno</td>\n",
       "      <td>norwegian</td>\n",
       "      <td>True</td>\n",
       "      <td>norwegian_ner</td>\n",
       "      <td>norwegian</td>\n",
       "      <td>nynorsk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samnorsk</th>\n",
       "      <td>samnorsk</td>\n",
       "      <td>samnorsk</td>\n",
       "      <td>norwegian</td>\n",
       "      <td>True</td>\n",
       "      <td>norwegian_ner</td>\n",
       "      <td>norwegian</td>\n",
       "      <td>samnorsk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lang      code  langgroup huggingface        dataset     region  \\\n",
       "nob        bokmaal       nob  norwegian        True  norwegian_ner  norwegian   \n",
       "nno        nynorsk       nno  norwegian        True  norwegian_ner  norwegian   \n",
       "samnorsk  samnorsk  samnorsk  norwegian        True  norwegian_ner  norwegian   \n",
       "\n",
       "         train_lang  \n",
       "nob         bokmaal  \n",
       "nno         nynorsk  \n",
       "samnorsk   samnorsk  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ud_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6486134c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset norwegian_ner/bokmaal to .cache/norwegian_ner/bokmaal/1.0.0/d326c5669fdd52e99c78eaa6c9c8a8758a48f7494bf59ed17e12814eb349e443...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 689.02it/s]\n",
      "Extracting data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1202.96it/s]\n",
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset norwegian_ner downloaded and prepared to .cache/norwegian_ner/bokmaal/1.0.0/d326c5669fdd52e99c78eaa6c9c8a8758a48f7494bf59ed17e12814eb349e443. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 805.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset norwegian_ner/nynorsk to .cache/norwegian_ner/nynorsk/1.0.0/d326c5669fdd52e99c78eaa6c9c8a8758a48f7494bf59ed17e12814eb349e443...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 7612.17it/s]\n",
      "Extracting data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1348.94it/s]\n",
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset norwegian_ner downloaded and prepared to .cache/norwegian_ner/nynorsk/1.0.0/d326c5669fdd52e99c78eaa6c9c8a8758a48f7494bf59ed17e12814eb349e443. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 827.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset norwegian_ner/samnorsk to .cache/norwegian_ner/samnorsk/1.0.0/d326c5669fdd52e99c78eaa6c9c8a8758a48f7494bf59ed17e12814eb349e443...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 3750.50it/s]\n",
      "Extracting data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1490.87it/s]\n",
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset norwegian_ner downloaded and prepared to .cache/norwegian_ner/samnorsk/1.0.0/d326c5669fdd52e99c78eaa6c9c8a8758a48f7494bf59ed17e12814eb349e443. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 687.59it/s]\n"
     ]
    }
   ],
   "source": [
    "script=\"scripts/ner/norwegian_ner.py\"\n",
    "ud_ones=all_lang[(all_lang['huggingface']==True) & (all_lang['dataset']=='norwegian_ner')]\n",
    "for lang in ud_ones['lang']:\n",
    "    dataset = load_dataset(script, lang,\n",
    "            cache_dir=CACHE_DIR)\n",
    "    for key in dataset.keys():\n",
    "        counts[key]+=len(dataset[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f8e38d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 459640, 'validation': 190200, 'test': 226841} 89\n"
     ]
    }
   ],
   "source": [
    "print(counts, len(all_lang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32e827dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikiann (.cache/wikiann/ar/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 988.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
      "        num_rows: 20000\n",
      "    })\n",
      "})\n",
      "[['تعلم', 'في', 'جامعة', 'نورث', 'وسترن', 'في', '.'], ['تحويل', 'ده\\u200cشهر', '(', 'مقاطعة', 'كلاردشت', ')']]\n",
      "[[0, 0, 3, 4, 4, 4, 0], [0, 5, 6, 6, 6, 6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## for langs not present in huggingface wikiann [huggingface=True]\n",
    "lang='ar' \n",
    "script=\"scripts/ner/wikiann_og.py\"\n",
    "predict_dataset = load_dataset(script, lang, cache_dir=CACHE_DIR)\n",
    "print(predict_dataset)\n",
    "print(predict_dataset['test']['tokens'][:2])\n",
    "print(predict_dataset['test']['ner_tags'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6466b8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikiann_og/kab to .cache/wikiann_og/kab/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7...\n",
      "<datasets.download.download_manager.ArchiveIterable object at 0x7fa042433d90>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikiann_og downloaded and prepared to .cache/wikiann_og/kab/1.1.0/bd5069ae42633af8e332aa82fb4f866eafd1dffc876e6bae94c18978db74e5d7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 792.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'ner_tags'],\n",
      "        num_rows: 3004\n",
      "    })\n",
      "})\n",
      "[['Aṣqif', 'n', 'Ṭmana'], ['Tizi', 'Wezzu']]\n",
      "[[5, 6, 6], [5, 6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## for test langs not present in huggingface wikiann [huggingface=False]\n",
    "lang='kab' \n",
    "script=\"scripts/ner/wikiann_og.py\"\n",
    "predict_dataset = load_dataset(script, lang, cache_dir=CACHE_DIR)\n",
    "print(predict_dataset)\n",
    "print(predict_dataset['test']['tokens'][:2])\n",
    "print(predict_dataset['test']['ner_tags'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "524357ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset norwegian_ner/bokmaal to .cache/norwegian_ner/bokmaal/1.0.0/d326c5669fdd52e99c78eaa6c9c8a8758a48f7494bf59ed17e12814eb349e443...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1908.24it/s]\n",
      "Extracting data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1174.22it/s]\n",
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset norwegian_ner downloaded and prepared to .cache/norwegian_ner/bokmaal/1.0.0/d326c5669fdd52e99c78eaa6c9c8a8758a48f7494bf59ed17e12814eb349e443. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 516.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['idx', 'text', 'tokens', 'lemmas', 'pos_tags', 'ner_tags'],\n",
      "        num_rows: 15696\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['idx', 'text', 'tokens', 'lemmas', 'pos_tags', 'ner_tags'],\n",
      "        num_rows: 2410\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['idx', 'text', 'tokens', 'lemmas', 'pos_tags', 'ner_tags'],\n",
      "        num_rows: 1939\n",
      "    })\n",
      "})\n",
      "[['Honnørordene', 'er', '\"', 'dristig', 'formspråk', '\"', ',', '\"', 'nyskapning', '\"', 'og', '\"', 'livgivende', 'kontrast', '\"', '.'], ['Jeg', 'ser', 'et', 'landskap', 'som', 'er', 'såret', 'og', 'i', 'tilbaketrekning', '.']]\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## for NORWEGIAN_NER all_lang[all_lang['dataset']=='norwegian_ner']\n",
    "lang='bokmaal' \n",
    "script=\"scripts/ner/norwegian_ner.py\"\n",
    "predict_dataset = load_dataset(script, lang, cache_dir=CACHE_DIR)\n",
    "print(predict_dataset)\n",
    "print(predict_dataset['test']['tokens'][:2])\n",
    "print(predict_dataset['test']['ner_tags'][:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be9700b",
   "metadata": {},
   "source": [
    "### 4. dialect identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6483a46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arabic\n",
      "train.csv\n",
      "{'KHA': 1600, 'RAB': 1600, 'DOH': 1600, 'DAM': 1600, 'ALX': 1600, 'AMM': 1600, 'SAL': 1600, 'JER': 1600, 'TUN': 1600, 'MUS': 1600, 'BAS': 1600, 'FES': 1600, 'TRI': 1600, 'ASW': 1600, 'MSA': 1600, 'BEI': 1600, 'RIY': 1600, 'BAG': 1600, 'BEN': 1600, 'SFX': 1600, 'ALE': 1600, 'MOS': 1600, 'CAI': 1600, 'JED': 1600, 'ALG': 1600, 'SAN': 1600}\n",
      "\n",
      "dev.csv\n",
      "{'ASW': 200, 'BAS': 200, 'JER': 200, 'AMM': 200, 'TUN': 200, 'JED': 200, 'RAB': 200, 'SFX': 200, 'MSA': 200, 'DAM': 200, 'ALG': 200, 'BEI': 200, 'TRI': 200, 'KHA': 200, 'SAL': 200, 'RIY': 200, 'ALE': 200, 'MUS': 200, 'BEN': 200, 'MOS': 200, 'BAG': 200, 'FES': 200, 'CAI': 200, 'DOH': 200, 'SAN': 200, 'ALX': 200}\n",
      "\n",
      "test.csv\n",
      "{'SAN': 200, 'JER': 200, 'BEI': 200, 'SAL': 200, 'AMM': 200, 'BAG': 200, 'RIY': 200, 'ALE': 200, 'MUS': 200, 'SFX': 200, 'ALG': 200, 'BAS': 200, 'JED': 200, 'TRI': 200, 'MOS': 200, 'ALX': 200, 'FES': 200, 'CAI': 200, 'TUN': 200, 'RAB': 200, 'MSA': 200, 'KHA': 200, 'DOH': 200, 'ASW': 200, 'DAM': 200, 'BEN': 200}\n",
      "\n",
      "mandarin_traditional\n",
      "dev.csv\n",
      "{'M': 1000, 'T': 1000}\n",
      "\n",
      "train.csv\n",
      "{'M': 1000, 'T': 1000}\n",
      "\n",
      "\n",
      "swiss-dialects\n",
      "test.csv\n",
      "{'BE': 380, 'BS': 351, 'LU': 347, 'ZH': 345}\n",
      "\n",
      "train.csv\n",
      "{'BS': 848, 'ZH': 832, 'LU': 829, 'BE': 811}\n",
      "\n",
      "\n",
      "english\n",
      "dev.csv\n",
      "{'EN-US': 312, 'EN-GB': 211, 'EN': 76}\n",
      "\n",
      "train.csv\n",
      "{'EN-US': 312, 'EN-GB': 211, 'EN': 76}\n",
      "\n",
      "\n",
      "greek\n",
      "test.csv\n",
      "{'smg_twitter': 59, 'cg_other': 58, 'cg_twitter': 45, 'cg_fb': 30, 'smg_other': 23, 'smg_fb': 12}\n",
      "\n",
      "train.csv\n",
      "{'smg_twitter': 146, 'cg_other': 137, 'cg_twitter': 108, 'cg_fb': 54, 'smg_other': 52, 'smg_fb': 30}\n",
      "\n",
      "\n",
      "portuguese\n",
      "portuguese-dev.csv\n",
      "{'PT-BR': 588, 'PT-PT': 269, 'PT': 134}\n",
      "\n",
      "dev.csv\n",
      "{'PT-BR': 588, 'PT-PT': 269, 'PT': 134}\n",
      "\n",
      "train.csv\n",
      "{'PT-BR': 588, 'PT-PT': 269, 'PT': 134}\n",
      "\n",
      "portuguese-train.csv\n",
      "{'PT-BR': 588, 'PT-PT': 269, 'PT': 134}\n",
      "\n",
      "\n",
      "mandarin_simplified\n",
      "dev.csv\n",
      "{'M': 1000, 'T': 1000}\n",
      "\n",
      "train.csv\n",
      "{'M': 1000, 'T': 1000}\n",
      "\n",
      "\n",
      "spanish\n",
      "dev.csv\n",
      "{'ES-ES': 444, 'ES': 318, 'ES-AR': 227}\n",
      "\n",
      "train.csv\n",
      "{'ES-ES': 444, 'ES': 318, 'ES-AR': 227}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counts={'train.csv':0,'dev.csv':0,'test.csv':0}\n",
    "count_lang=0\n",
    "arabic='data/dialect-identification/arabic/MADAR/MADAR_Corpus'\n",
    "print('arabic')\n",
    "count_lang+=1\n",
    "for f in ['train.csv','dev.csv','test.csv']:\n",
    "    print(f)\n",
    "    df=pd.read_csv(os.path.join(arabic,f))\n",
    "    counts[str(f)]+=len(df)\n",
    "    print(dict(df['label'].value_counts()))\n",
    "    print()\n",
    "    \n",
    "root='data/dialect-identification/'\n",
    "for f in os.listdir(root):\n",
    "    if f!='arabic' and not str(f).startswith('.'):\n",
    "        print(f)\n",
    "        count_lang+=1\n",
    "        for f1 in os.listdir(os.path.join(root,f)):\n",
    "            print(f1)\n",
    "            df=pd.read_csv(os.path.join(root,f,f1))\n",
    "            if str(f1) in ['train.csv','dev.csv','test.csv']:\n",
    "                counts[str(f1)]+=len(df)\n",
    "            print(dict(df['label'].value_counts()))\n",
    "            print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ce836ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train.csv': 52026, 'dev.csv': 11779, 'test.csv': 6850} 8\n"
     ]
    }
   ],
   "source": [
    "print(counts,count_lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0484204",
   "metadata": {},
   "source": [
    "### 5. question-anwering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02dfe75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datapath='data/Question-Answering/SDQA-gold-task/sdqa-train-all.json'\n",
    "dev_datapath='data/Question-Answering/SDQA-gold-task/sdqa-dev-all.json'\n",
    "test_datapath='data/Question-Answering/SDQA-gold-task/sdqa-test-all.json'\n",
    "language_dialect_identifier=\"{lang}-id-{dialect}\" #look at id field, eg: \"english-6037841464917965779-nga\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed6f5cd",
   "metadata": {},
   "source": [
    "### 6. sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "796dbded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arabic\n",
      "aeb_Latn-train.csv\n",
      "{'positive': 36942, 'negative': 30589, 'neutral': 2468}\n",
      "\n",
      "arb_arab-train.csv\n",
      "{'positive': 4797, 'neutral': 1923, 'negative': 1783, 'mixed': 324}\n",
      "\n",
      "arq_arab-test.csv\n",
      "{'negative': 7512, 'positive': 7448}\n",
      "\n",
      "ar-lb_arab-test.csv\n",
      "{5: 665, 4: 232, 3: 142, 1: 99, 2: 37}\n",
      "\n",
      "aeb_Arab-test.csv\n",
      "{'positive': 1701, 'negative': 1701}\n",
      "\n",
      "sau_arab-train.csv\n",
      "{'negative': 6080, 'positive': 1487, 'neutral': 866}\n",
      "\n",
      "jor_arab-test.csv\n",
      "{'positive': 295, 'negative': 245}\n",
      "\n",
      "ary_arab-test.csv\n",
      "{'positive': 914, 'neutral': 389, 'negative': 279, 'mixed': 58}\n",
      "\n",
      "jor_arab-train.csv\n",
      "{'negative': 655, 'positive': 605}\n",
      "\n",
      "aeb_Latn-test.csv\n",
      "{'positive': 15769, 'negative': 13178, 'neutral': 1054}\n",
      "\n",
      "ar-lb_arab-train.csv\n",
      "{5: 1648, 4: 502, 3: 276, 1: 204, 2: 111}\n",
      "\n",
      "arz_arab-test.csv\n",
      "{'objective': 2028, 'negative': 486, 'neutral': 254, 'positive': 235}\n",
      "\n",
      "arz_arab-train.csv\n",
      "{'objective': 4663, 'negative': 1198, 'neutral': 578, 'positive': 564}\n",
      "\n",
      "aeb_Arab-train.csv\n",
      "{'positive': 7155, 'negative': 6516}\n",
      "\n",
      "arb_arab-test.csv\n",
      "{'positive': 2103, 'neutral': 805, 'negative': 740, 'mixed': 136}\n",
      "\n",
      "ary_arab-train.csv\n",
      "{'positive': 2076, 'neutral': 920, 'negative': 703, 'mixed': 125}\n",
      "\n",
      "sau_arab-test.csv\n",
      "{'negative': 2589, 'positive': 656, 'neutral': 370}\n",
      "\n",
      "arq_arab-train.csv\n",
      "{'positive': 17484, 'negative': 17420}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counts={'train.csv':0,'dev.csv':0,'test.csv':0}\n",
    "arabic='data/sentiment_analysis/arabic'\n",
    "print('arabic')\n",
    "for f in os.listdir(arabic):\n",
    "    print(f)\n",
    "    df=pd.read_csv(os.path.join(arabic,f))\n",
    "    for split in counts.keys():\n",
    "        if str(f).endswith(split):\n",
    "            counts[split]+=len(df)\n",
    "    print(dict(df['label'].value_counts()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bd36566d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train.csv': 150664, 'dev.csv': 0, 'test.csv': 62120}\n"
     ]
    }
   ],
   "source": [
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bca54e3",
   "metadata": {},
   "source": [
    "### 7. topic classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc0bcb",
   "metadata": {},
   "source": [
    "- we train one lang per group (identifier: langgroup) and evaluate on all other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffbcae4",
   "metadata": {},
   "source": [
    "#### we only consider the following languages from the sib-200 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7a5e45ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "f = open('metadata/topic_metadata.json')\n",
    "metadata = json.load(f)\n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "96f158dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>code</th>\n",
       "      <th>langgroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lmo_Latn</th>\n",
       "      <td>lombard</td>\n",
       "      <td>lmo_Latn</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eng_Latn</th>\n",
       "      <td>English</td>\n",
       "      <td>eng_Latn</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ita_Latn</th>\n",
       "      <td>italian</td>\n",
       "      <td>ita_Latn</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fur_Latn</th>\n",
       "      <td>friulian</td>\n",
       "      <td>fur_Latn</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scn_Latn</th>\n",
       "      <td>sicilian</td>\n",
       "      <td>scn_Latn</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>srd_Latn</th>\n",
       "      <td>sardinian</td>\n",
       "      <td>srd_Latn</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vec_Latn</th>\n",
       "      <td>venetian</td>\n",
       "      <td>vec_Latn</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>azb_Arab</th>\n",
       "      <td>south</td>\n",
       "      <td>azb_Arab</td>\n",
       "      <td>azarbaijani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>azj_Latn</th>\n",
       "      <td>north</td>\n",
       "      <td>azj_Latn</td>\n",
       "      <td>azarbaijani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tur_Latn</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>tur_Latn</td>\n",
       "      <td>azarbaijani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kmr_Latn</th>\n",
       "      <td>northern</td>\n",
       "      <td>kmr_Latn</td>\n",
       "      <td>kurdish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ckb_Arab</th>\n",
       "      <td>central</td>\n",
       "      <td>ckb_Arab</td>\n",
       "      <td>kurdish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nno_Latn</th>\n",
       "      <td>nynorsk</td>\n",
       "      <td>nno_Latn</td>\n",
       "      <td>norwegian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nob_Latn</th>\n",
       "      <td>bokmal</td>\n",
       "      <td>nob_Latn</td>\n",
       "      <td>norwegian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lim_Latn</th>\n",
       "      <td>limburgish</td>\n",
       "      <td>lim_Latn</td>\n",
       "      <td>dutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ltz_Latn</th>\n",
       "      <td>luxermburgish</td>\n",
       "      <td>ltz_Latn</td>\n",
       "      <td>dutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nld_Latn</th>\n",
       "      <td>dutch</td>\n",
       "      <td>nld_Latn</td>\n",
       "      <td>dutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lvs_Latn</th>\n",
       "      <td>standard</td>\n",
       "      <td>lvs_Latn</td>\n",
       "      <td>latvian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ltg_Latn</th>\n",
       "      <td>latgalian</td>\n",
       "      <td>ltg_Latn</td>\n",
       "      <td>latvian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acm_Arab</th>\n",
       "      <td>Mesopotamian Arabic</td>\n",
       "      <td>acm_Arab</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acq_Arab</th>\n",
       "      <td>Ta’izzi-Adeni Arabic</td>\n",
       "      <td>acq_Arab</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aeb_Arab</th>\n",
       "      <td>Tunisian Arabic</td>\n",
       "      <td>aeb_Arab</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ajp_Arab</th>\n",
       "      <td>South Levantine Arabic</td>\n",
       "      <td>ajp_Arab</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apc_Arab</th>\n",
       "      <td>North Levantine Arabic</td>\n",
       "      <td>apc_Arab</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arb_Arab</th>\n",
       "      <td>MSA (Arabic)</td>\n",
       "      <td>arb_Arab</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ars_Arab</th>\n",
       "      <td>Najdi Arabic</td>\n",
       "      <td>ars_Arab</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ary_Arab</th>\n",
       "      <td>Moroccan Arabic</td>\n",
       "      <td>ary_Arab</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arz_Arab</th>\n",
       "      <td>Egyptian Arabic</td>\n",
       "      <td>arz_Arab</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kab_Latn</th>\n",
       "      <td>Kabyle</td>\n",
       "      <td>kab_Latn</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lij_Latn</th>\n",
       "      <td>Ligurian</td>\n",
       "      <td>lij_Latn</td>\n",
       "      <td>Franco-Provencal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oci_Latn</th>\n",
       "      <td>Occitan</td>\n",
       "      <td>oci_Latn</td>\n",
       "      <td>Franco-Provencal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yue_Hant</th>\n",
       "      <td>Yue Chinese</td>\n",
       "      <td>yue_Hant</td>\n",
       "      <td>chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zho_Hans</th>\n",
       "      <td>Chinese (Simplified)</td>\n",
       "      <td>zho_Hans</td>\n",
       "      <td>chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zho_Hant</th>\n",
       "      <td>Chinese (Traditional)</td>\n",
       "      <td>zho_Hant</td>\n",
       "      <td>chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glg_Latn</th>\n",
       "      <td>Galician</td>\n",
       "      <td>glg_Latn</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spa_Latn</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>spa_Latn</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>por_Latn</th>\n",
       "      <td>Portuguese</td>\n",
       "      <td>por_Latn</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nso_Latn</th>\n",
       "      <td>Northern Sotho</td>\n",
       "      <td>nso_Latn</td>\n",
       "      <td>sotho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sot_Latn</th>\n",
       "      <td>Southern Sotho</td>\n",
       "      <td>sot_Latn</td>\n",
       "      <td>sotho</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            lang      code         langgroup\n",
       "lmo_Latn                 lombard  lmo_Latn           italian\n",
       "eng_Latn                 English  eng_Latn           English\n",
       "ita_Latn                 italian  ita_Latn           italian\n",
       "fur_Latn                friulian  fur_Latn           italian\n",
       "scn_Latn                sicilian  scn_Latn           italian\n",
       "srd_Latn               sardinian  srd_Latn           italian\n",
       "vec_Latn                venetian  vec_Latn           italian\n",
       "azb_Arab                   south  azb_Arab       azarbaijani\n",
       "azj_Latn                   north  azj_Latn       azarbaijani\n",
       "tur_Latn                 Turkish  tur_Latn       azarbaijani\n",
       "kmr_Latn                northern  kmr_Latn           kurdish\n",
       "ckb_Arab                 central  ckb_Arab           kurdish\n",
       "nno_Latn                 nynorsk  nno_Latn         norwegian\n",
       "nob_Latn                  bokmal  nob_Latn         norwegian\n",
       "lim_Latn              limburgish  lim_Latn             dutch\n",
       "ltz_Latn           luxermburgish  ltz_Latn             dutch\n",
       "nld_Latn                   dutch  nld_Latn             dutch\n",
       "lvs_Latn                standard  lvs_Latn           latvian\n",
       "ltg_Latn               latgalian  ltg_Latn           latvian\n",
       "acm_Arab     Mesopotamian Arabic  acm_Arab            arabic\n",
       "acq_Arab    Ta’izzi-Adeni Arabic  acq_Arab            arabic\n",
       "aeb_Arab         Tunisian Arabic  aeb_Arab            arabic\n",
       "ajp_Arab  South Levantine Arabic  ajp_Arab            arabic\n",
       "apc_Arab  North Levantine Arabic  apc_Arab            arabic\n",
       "arb_Arab            MSA (Arabic)  arb_Arab            arabic\n",
       "ars_Arab            Najdi Arabic  ars_Arab            arabic\n",
       "ary_Arab         Moroccan Arabic  ary_Arab            arabic\n",
       "arz_Arab         Egyptian Arabic  arz_Arab            arabic\n",
       "kab_Latn                  Kabyle  kab_Latn            arabic\n",
       "lij_Latn                Ligurian  lij_Latn  Franco-Provencal\n",
       "oci_Latn                 Occitan  oci_Latn  Franco-Provencal\n",
       "yue_Hant             Yue Chinese  yue_Hant           chinese\n",
       "zho_Hans    Chinese (Simplified)  zho_Hans           chinese\n",
       "zho_Hant   Chinese (Traditional)  zho_Hant           chinese\n",
       "glg_Latn                Galician  glg_Latn           Spanish\n",
       "spa_Latn                 Spanish  spa_Latn           Spanish\n",
       "por_Latn              Portuguese  por_Latn           Spanish\n",
       "nso_Latn          Northern Sotho  nso_Latn             sotho\n",
       "sot_Latn          Southern Sotho  sot_Latn             sotho"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lang=pd.DataFrame(metadata).T\n",
    "all_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "612d9580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "lmo_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "lmo_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "lmo_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "eng_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "eng_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "eng_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "ita_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "ita_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "ita_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "fur_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "fur_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "fur_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "scn_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "scn_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "scn_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "srd_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "srd_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "srd_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "vec_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "vec_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "vec_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "azb_Arab test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "azb_Arab dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "azb_Arab train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "azj_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "azj_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "azj_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "tur_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "tur_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "tur_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "kmr_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "kmr_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "kmr_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "ckb_Arab test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "ckb_Arab dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "ckb_Arab train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "nno_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "nno_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "nno_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "nob_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "nob_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "nob_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "lim_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "lim_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "lim_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "ltz_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "ltz_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "ltz_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "nld_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "nld_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "nld_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "lvs_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "lvs_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "lvs_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "ltg_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "ltg_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "ltg_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "acm_Arab test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "acm_Arab dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "acm_Arab train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "acq_Arab test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "acq_Arab dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "acq_Arab train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "aeb_Arab test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "aeb_Arab dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "aeb_Arab train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "ajp_Arab test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "ajp_Arab dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "ajp_Arab train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "apc_Arab test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "apc_Arab dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "apc_Arab train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "arb_Arab test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "arb_Arab dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "arb_Arab train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "ars_Arab test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "ars_Arab dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "ars_Arab train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "ary_Arab test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "ary_Arab dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "ary_Arab train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "arz_Arab test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "arz_Arab dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "arz_Arab train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "kab_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "kab_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "kab_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "lij_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "lij_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "lij_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "oci_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "oci_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "oci_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "yue_Hant test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "yue_Hant dev.csv 99\n",
      "train.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "yue_Hant train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "zho_Hans test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "zho_Hans dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "zho_Hans train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "zho_Hant test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "zho_Hant dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "zho_Hant train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "glg_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "glg_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "glg_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "spa_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "spa_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "spa_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "por_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "por_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "por_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "nso_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "nso_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "nso_Latn train.csv 701\n",
      "test.csv\n",
      "{'science/technology': 51, 'travel': 40, 'politics': 30, 'sports': 25, 'health': 22, 'entertainment': 19, 'geography': 17}\n",
      "\n",
      "sot_Latn test.csv 204\n",
      "dev.csv\n",
      "{'science/technology': 25, 'travel': 20, 'politics': 14, 'sports': 12, 'health': 11, 'entertainment': 9, 'geography': 8}\n",
      "\n",
      "sot_Latn dev.csv 99\n",
      "train.csv\n",
      "{'science/technology': 176, 'travel': 138, 'politics': 102, 'sports': 85, 'health': 77, 'entertainment': 65, 'geography': 58}\n",
      "\n",
      "sot_Latn train.csv 701\n"
     ]
    }
   ],
   "source": [
    "counts={'train.csv':0,'dev.csv':0,'test.csv':0}\n",
    "datapath='data/topic_class'\n",
    "lang='lmo_Latn'\n",
    "for lang in all_lang['code']:\n",
    "    for f in os.listdir(os.path.join(datapath, lang)):\n",
    "        if f!='labels.txt':\n",
    "            print(f)\n",
    "            df=pd.read_csv(os.path.join(datapath,lang,f))\n",
    "            print(dict(df['label'].value_counts()))\n",
    "            print()\n",
    "            counts[str(f)]+=len(df)\n",
    "            print(lang,f, len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c4a01a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train.csv': 27339, 'dev.csv': 3861, 'test.csv': 7956} 39\n"
     ]
    }
   ],
   "source": [
    "print(counts, len(all_lang))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90834de",
   "metadata": {},
   "source": [
    "### 8. reading comprehension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e696fe",
   "metadata": {},
   "source": [
    "- we only consider the following evaluation languages from Belebele dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e634ddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('metadata/rcmc_metadata.json')\n",
    "metadata = json.load(f)\n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "88ce1c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>code</th>\n",
       "      <th>langgroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zho_Hans</th>\n",
       "      <td>Chinese (Simplified)</td>\n",
       "      <td>zho_Hans</td>\n",
       "      <td>chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zho_Hant</th>\n",
       "      <td>Chinese (Traditional)</td>\n",
       "      <td>zho_Hant</td>\n",
       "      <td>chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eng_Latn</th>\n",
       "      <td>English</td>\n",
       "      <td>eng_Latn</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nso_Latn</th>\n",
       "      <td>Northern Sotho</td>\n",
       "      <td>nso_Latn</td>\n",
       "      <td>sotho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sot_Latn</th>\n",
       "      <td>Southern Sotho</td>\n",
       "      <td>sot_Latn</td>\n",
       "      <td>sotho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acm_Arab</th>\n",
       "      <td>Mesopotamian Arabic</td>\n",
       "      <td>acm_Arab</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apc_Arab</th>\n",
       "      <td>North Levantine Arabic</td>\n",
       "      <td>apc_Arab</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arb_Arab</th>\n",
       "      <td>MSA (Arabic)</td>\n",
       "      <td>arb_Arab</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ars_Arab</th>\n",
       "      <td>Najdi Arabic</td>\n",
       "      <td>ars_Arab</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ary_Arab</th>\n",
       "      <td>Moroccan Arabic</td>\n",
       "      <td>ary_Arab</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            lang      code langgroup\n",
       "zho_Hans    Chinese (Simplified)  zho_Hans   chinese\n",
       "zho_Hant   Chinese (Traditional)  zho_Hant   chinese\n",
       "eng_Latn                 English  eng_Latn   English\n",
       "nso_Latn          Northern Sotho  nso_Latn     sotho\n",
       "sot_Latn          Southern Sotho  sot_Latn     sotho\n",
       "acm_Arab     Mesopotamian Arabic  acm_Arab    arabic\n",
       "apc_Arab  North Levantine Arabic  apc_Arab    arabic\n",
       "arb_Arab            MSA (Arabic)  arb_Arab    arabic\n",
       "ars_Arab            Najdi Arabic  ars_Arab    arabic\n",
       "ary_Arab         Moroccan Arabic  ary_Arab    arabic"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lang=pd.DataFrame(metadata).T\n",
    "all_lang.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39385c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'link': 'https:\\\\/\\\\/en.wikibooks.org\\\\/wiki\\\\/Accordion\\\\/Right_hand', 'question_number': 1, 'flores_passage': \"Make sure your hand is as relaxed as possible while still hitting all the notes correctly - also try not to make much extraneous motion with your fingers. This way, you will tire yourself out as little as possible. Remember there's no need to hit the keys with a lot of force for extra volume like on the piano. On the accordion, to get extra volume, you use the bellows with more pressure or speed.\", 'question': 'According to the passage, what would not be considered an accurate tip for successfully playing the accordion?', 'mc_answer1': 'For additional volume, increase the force with which you hit the keys', 'mc_answer2': 'Keep unnecessary movement to a minimum in order to preserve your stamina', 'mc_answer3': 'Be mindful of hitting the notes while maintaining a relaxed hand', 'mc_answer4': 'Increase the speed with which you operate the bellows to achieve extra volume', 'correct_answer_num': '1', 'dialect': 'eng_Latn', 'ds': '2023-05-03'}\n"
     ]
    }
   ],
   "source": [
    "datapath='datapath/reading-comprehension/Belebele'\n",
    "sample_test_file='arb_Arab.jsonl'\n",
    "first_example={\"link\":\"https:\\/\\/en.wikibooks.org\\/wiki\\/Accordion\\/Right_hand\",\"question_number\":1,\"flores_passage\":\"Make sure your hand is as relaxed as possible while still hitting all the notes correctly - also try not to make much extraneous motion with your fingers. This way, you will tire yourself out as little as possible. Remember there's no need to hit the keys with a lot of force for extra volume like on the piano. On the accordion, to get extra volume, you use the bellows with more pressure or speed.\",\"question\":\"According to the passage, what would not be considered an accurate tip for successfully playing the accordion?\",\"mc_answer1\":\"For additional volume, increase the force with which you hit the keys\",\"mc_answer2\":\"Keep unnecessary movement to a minimum in order to preserve your stamina\",\"mc_answer3\":\"Be mindful of hitting the notes while maintaining a relaxed hand\",\"mc_answer4\":\"Increase the speed with which you operate the bellows to achieve extra volume\",\"correct_answer_num\":\"1\",\"dialect\":\"eng_Latn\",\"ds\":\"2023-05-03\"}\n",
    "print(first_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "71339038",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_file=datapath='datapath/reading-comprehension/Belebele/train.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3918c5d2",
   "metadata": {},
   "source": [
    "### 9. Natural language Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbeb928",
   "metadata": {},
   "source": [
    "- we perform cross-lingual transfer on translate-test langs from eng_Latn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d01f0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('metadata/nli_metadata.json')\n",
    "metadata = json.load(f)\n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "485cab84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>code</th>\n",
       "      <th>langgroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lmo_Latn</th>\n",
       "      <td>lombard</td>\n",
       "      <td>lmo_Latn</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eng_Latn</th>\n",
       "      <td>English</td>\n",
       "      <td>eng_Latn</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ita_Latn</th>\n",
       "      <td>italian</td>\n",
       "      <td>ita_Latn</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fur_Latn</th>\n",
       "      <td>friulian</td>\n",
       "      <td>fur_Latn</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scn_Latn</th>\n",
       "      <td>sicilian</td>\n",
       "      <td>scn_Latn</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>srd_Latn</th>\n",
       "      <td>sardinian</td>\n",
       "      <td>srd_Latn</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vec_Latn</th>\n",
       "      <td>venetian</td>\n",
       "      <td>vec_Latn</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>azb_Arab</th>\n",
       "      <td>south</td>\n",
       "      <td>azb_Arab</td>\n",
       "      <td>azarbaijani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>azj_Latn</th>\n",
       "      <td>north</td>\n",
       "      <td>azj_Latn</td>\n",
       "      <td>azarbaijani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tur_Latn</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>tur_Latn</td>\n",
       "      <td>azarbaijani</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lang      code    langgroup\n",
       "lmo_Latn    lombard  lmo_Latn      italian\n",
       "eng_Latn    English  eng_Latn      English\n",
       "ita_Latn    italian  ita_Latn      italian\n",
       "fur_Latn   friulian  fur_Latn      italian\n",
       "scn_Latn   sicilian  scn_Latn      italian\n",
       "srd_Latn  sardinian  srd_Latn      italian\n",
       "vec_Latn   venetian  vec_Latn      italian\n",
       "azb_Arab      south  azb_Arab  azarbaijani\n",
       "azj_Latn      north  azj_Latn  azarbaijani\n",
       "tur_Latn    Turkish  tur_Latn  azarbaijani"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lang=pd.DataFrame(metadata).T\n",
    "all_lang.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "798883f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eval_langs=[\"eng_Latn\",\"lmo_Latn\",\"ita_Latn\",\"fur_Latn\",\"scn_Latn\",\"srd_Latn\",\"vec_Latn\",\"azb_Arab\",\"azj_Latn\",\"tur_Latn\",\"kmr_Latn\",\"ckb_Arab\",\"nno_Latn\",\"nob_Latn\",\"lim_Latn\",\"ltz_Latn\",\"nld_Latn\",\"lvs_Latn\",\"ltg_Latn\",\"acm_Arab\",\"acq_Arab\",\"aeb_Arab\",\"ajp_Arab\",\"apc_Arab\",\"arb_Arab\",\"ars_Arab\",\"ary_Arab\",\"arz_Arab\",\"kab_Latn\",\"asm_Beng\",\"ben_Beng\",\"lij_Latn\",\"oci_Latn\",\"yue_Hant\",\"zho_Hans\",\"zho_Hant\",\"glg_Latn\",\"spa_Latn\",\"por_Latn\",\"nso_Latn\",\"sot_Latn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "525d417f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eng_Latn', 'lmo_Latn', 'ita_Latn', 'fur_Latn', 'scn_Latn', 'srd_Latn', 'vec_Latn', 'azb_Arab', 'azj_Latn', 'tur_Latn', 'kmr_Latn', 'ckb_Arab', 'nno_Latn', 'nob_Latn', 'lim_Latn', 'ltz_Latn', 'nld_Latn', 'lvs_Latn', 'ltg_Latn', 'acm_Arab', 'acq_Arab', 'aeb_Arab', 'ajp_Arab', 'apc_Arab', 'arb_Arab', 'ars_Arab', 'ary_Arab', 'arz_Arab', 'kab_Latn', 'asm_Beng', 'ben_Beng', 'lij_Latn', 'oci_Latn', 'yue_Hant', 'zho_Hans', 'zho_Hant', 'glg_Latn', 'spa_Latn', 'por_Latn', 'nso_Latn', 'sot_Latn']\n"
     ]
    }
   ],
   "source": [
    "print(all_eval_langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0836a9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lang='eng_Latn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "20665de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset dialect_nli (.cache/dialect_nli/eng_Latn/1.1.0/b69815628a902151a9f2b158e6be8fabf359868aa4a25c29c09ff689455041b9)\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 363.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label'],\n",
      "        num_rows: 392702\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label'],\n",
      "        num_rows: 5010\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label'],\n",
      "        num_rows: 2490\n",
      "    })\n",
      "})\n",
      "{'premise': Value(dtype='string', id=None), 'hypothesis': Value(dtype='string', id=None), 'label': ClassLabel(num_classes=3, names=['entailment', 'neutral', 'contradiction'], id=None)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lang=train_lang\n",
    "dataset = load_dataset(\"scripts/nli/dialect_nli.py\", lang,\n",
    "            cache_dir=CACHE_DIR)\n",
    "print(dataset)\n",
    "print(dataset['train'].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0c9be61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset dialect_nli (.cache/dialect_nli/lmo_Latn/1.1.0/b69815628a902151a9f2b158e6be8fabf359868aa4a25c29c09ff689455041b9)\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 963.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label'],\n",
      "        num_rows: 0\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label'],\n",
      "        num_rows: 5010\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label'],\n",
      "        num_rows: 0\n",
      "    })\n",
      "})\n",
      "{'premise': Value(dtype='string', id=None), 'hypothesis': Value(dtype='string', id=None), 'label': ClassLabel(num_classes=3, names=['entailment', 'neutral', 'contradiction'], id=None)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lang='lmo_Latn'\n",
    "dataset = load_dataset(\"scripts/nli/dialect_nli.py\", lang,\n",
    "            cache_dir=CACHE_DIR)\n",
    "print(dataset)\n",
    "print(dataset['test'].features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2461fc3d",
   "metadata": {},
   "source": [
    "### 10. Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b719e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vnv-adp-l",
   "language": "python",
   "name": "vnv-adp-l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
